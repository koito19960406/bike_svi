GRF tree object 
Number of training samples: 11632 
Variable splits: 
(1) split_variable: age_40_59  split_value: 0.218451 
  (2) split_variable: od_vehicle_count_log  split_value: 1.94591 
    (4) * num_samples: 326  avg_Y: 5.4 avg_W: 0.33 
    (5) split_variable: age_0_19  split_value: 0.168787 
      (8) * num_samples: 291  avg_Y: 7.1 avg_W: 0.17 
      (9) * num_samples: 496  avg_Y: 6.15 avg_W: 0.19 
  (3) split_variable: ss_sidewalk  split_value: 0 
    (6) split_variable: ss_wall  split_value: 0.00753212 
      (10) split_variable: slope_log  split_value: 1.1195 
        (14) * num_samples: 404  avg_Y: 4.96 avg_W: 0.39 
        (15) * num_samples: 439  avg_Y: 4.61 avg_W: 0.42 
      (11) split_variable: age_40_59  split_value: 0.25904 
        (16) * num_samples: 541  avg_Y: 4.45 avg_W: 0.28 
        (17) split_variable: age_40_59  split_value: 0.285307 
          (20) * num_samples: 454  avg_Y: 4.18 avg_W: 0.31 
          (21) * num_samples: 317  avg_Y: 4.49 avg_W: 0.41 
    (7) split_variable: IMD_score_log  split_value: 2.44898 
      (12) * num_samples: 323  avg_Y: 4.96 avg_W: 0.41 
      (13) split_variable: ss_visual_complexity  split_value: 0.637377 
        (18) split_variable: lu_commerce_developed  split_value: 0.268121 
          (22) * num_samples: 246  avg_Y: 4.95 avg_W: 0.63 
          (23) * num_samples: 715  avg_Y: 6.35 avg_W: 0.19 
        (19) split_variable: age_40_59  split_value: 0.258817 
          (24) * num_samples: 668  avg_Y: 5.93 avg_W: 0.22 
          (25) * num_samples: 596  avg_Y: 5.69 avg_W: 0.25 
